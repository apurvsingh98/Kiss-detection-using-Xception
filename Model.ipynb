{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXEkSK4Oum4m",
        "colab_type": "text"
      },
      "source": [
        "Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df5CAhl2OOt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tensorflow\n",
        "from keras import layers\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras import metrics\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.inception_v3 import InceptionV3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjdgZ77ju8uM",
        "colab_type": "text"
      },
      "source": [
        "Loading the model with an input of (197,197,3), where 197 is the width/height and 3 is the number of color channels(RGB)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zix25H1Du7C4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pre_trained_model = InceptionV3(input_shape = (197,197, 3),\n",
        "                                include_top = False,\n",
        "                                weights = 'imagenet' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK_DC3vcxI5D",
        "colab_type": "text"
      },
      "source": [
        "Layer definition "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GIgFHw_xKWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_layer.trainable = True\n",
        "last_output = last_layer.output\n",
        "\n",
        "\n",
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(1024, activation = 'relu')(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(256, activation = 'relu')(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(2, activation = 'softmax')(x)\n",
        "\n",
        "model = Model(pre_trained_model.input, x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nAfMOG6u1-y",
        "colab_type": "text"
      },
      "source": [
        "Defining training parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHDsOuXLxpQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "model.compile(optimizer = 'Adam',\n",
        "             loss = 'categorical_crossentropy',\n",
        "             metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcvr1wq3xvXA",
        "colab_type": "text"
      },
      "source": [
        "Directory of the training/Validation images used by ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69Xz9e63x3U6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = '/content/sample_data/AfterShoot/first'\n",
        "validation_dir = '/content/sample_data/AfterShoot/second'\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                  rotation_range = 40,\n",
        "                                  horizontal_flip = True,\n",
        "                                  vertical_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                   batch_size = 100,\n",
        "                                                   class_mode = 'categorical',\n",
        "                                                   target_size = (299, 299))\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                                   batch_size = 20,\n",
        "                                                   class_mode = 'categorical',\n",
        "                                                   target_size = (299, 299))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ND5Gaw3x7uX",
        "colab_type": "text"
      },
      "source": [
        "Fitting the data into the model to start the training process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEz7RNK3xus-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(train_generator, validation_data = validation_generator, steps_per_epoch = 100, epochs = 100, validation_steps = 20, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7xrNWpSEBdo",
        "colab_type": "text"
      },
      "source": [
        "#Saving the model\n",
        "Use hd5 extension to save all the model checkpoints, use no extension if only the model is required to do the final testing/implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6P6mzzoEC_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(<path>)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DdDUINI0Yp7",
        "colab_type": "text"
      },
      "source": [
        "Plotting the accuracy/validation metrics over epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHAjs5om0gk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('Agg')\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "fig1 = plt.gcf()\n",
        "plt.show()\n",
        "plt.draw()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
